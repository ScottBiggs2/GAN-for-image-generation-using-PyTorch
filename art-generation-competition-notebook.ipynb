{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pathway = os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-25T01:45:00.259071Z","iopub.execute_input":"2024-02-25T01:45:00.259467Z","iopub.status.idle":"2024-02-25T01:45:08.595025Z","shell.execute_reply.started":"2024-02-25T01:45:00.259438Z","shell.execute_reply":"2024-02-25T01:45:08.594060Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#%matplotlib inline\nimport argparse\nimport os\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torch.autograd import Variable\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nfrom IPython.display import HTML\nfrom IPython.display import clear_output\n\n\n# Set random seed for reproducibility\n\nmanualSeed = 999\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)\ntorch.use_deterministic_algorithms(True) # Needed for reproducible results","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:11.751534Z","iopub.execute_input":"2024-02-25T01:45:11.751914Z","iopub.status.idle":"2024-02-25T01:45:18.208455Z","shell.execute_reply.started":"2024-02-25T01:45:11.751885Z","shell.execute_reply":"2024-02-25T01:45:18.207101Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# data (path)\ndataset_name = 'gan-getting-started'\nroot = '../input/'+dataset_name\n\n# data (img)\nimg_height = 256\nimg_width = 256\nchannels = 3\nsample_interval = 1\n\nepoch = 0 \nn_epochs = 5 # number of epochs of training\nbatch_size = 1 # size of the batches\nlr = 0.0002 # adam : learning rate\nb1 = 0.5 # adam : decay of first order momentum of gradient\nb2 = 0.999 # adam : decay of first order momentum of gradient\ndecay_epoch = 3 # suggested default : 100 (suggested 'n_epochs' is 200)\n                 # epoch from which to start lr decay\n    \n# Lists to store losses for visualization\nG_losses = []\nD_losses = []\n\nn_cpu = 1 # number of cpu threads to use during batch generation","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:25.011984Z","iopub.execute_input":"2024-02-25T01:45:25.013434Z","iopub.status.idle":"2024-02-25T01:45:25.020141Z","shell.execute_reply.started":"2024-02-25T01:45:25.013394Z","shell.execute_reply":"2024-02-25T01:45:25.018772Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n        \n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features), \n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:28.380027Z","iopub.execute_input":"2024-02-25T01:45:28.380431Z","iopub.status.idle":"2024-02-25T01:45:28.387874Z","shell.execute_reply.started":"2024-02-25T01:45:28.380395Z","shell.execute_reply":"2024-02-25T01:45:28.386621Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class GeneratorResNet(nn.Module):\n    def __init__(self, input_shape, num_residual_block):\n        super(GeneratorResNet, self).__init__()\n        \n        channels = input_shape[0]\n        \n        # Initial Convolution Block\n        out_features = 64\n        model = [\n            nn.ReflectionPad2d(channels),\n            nn.Conv2d(channels, out_features, 7),\n            nn.InstanceNorm2d(out_features),\n            nn.ReLU(inplace=True)\n        ]\n        in_features = out_features\n        \n        # Downsampling\n        for _ in range(2):\n            out_features *= 2\n            model += [\n                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n        \n        # Residual blocks\n        for _ in range(num_residual_block):\n            model += [ResidualBlock(out_features)]\n            \n        # Upsampling\n        for _ in range(2):\n            out_features //= 2\n            model += [\n                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n                nn.ReLU(inplace=True)\n            ]\n            in_features = out_features\n            \n        # Output Layer\n        model += [nn.ReflectionPad2d(channels),\n                  nn.Conv2d(out_features, channels, 7),\n                  nn.Tanh()\n                 ]\n        \n        # Unpacking\n        self.model = nn.Sequential(*model) \n        \n    def forward(self, x):\n        return self.model(x)\n\n#     TEST CODE : nn.Upsample","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:30.674723Z","iopub.execute_input":"2024-02-25T01:45:30.675098Z","iopub.status.idle":"2024-02-25T01:45:30.686256Z","shell.execute_reply.started":"2024-02-25T01:45:30.675072Z","shell.execute_reply":"2024-02-25T01:45:30.685091Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n        \n        channels, height, width = input_shape\n        \n        # Calculate output shape of image discriminator (PatchGAN)\n        self.output_shape = (1, height//2**4, width//2**4)\n        \n        def discriminator_block(in_filters, out_filters, normalize=True):\n            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n        \n        self.model = nn.Sequential(\n            *discriminator_block(channels, 64, normalize=False),\n            *discriminator_block(64, 128),\n            *discriminator_block(128,256),\n            *discriminator_block(256,512),\n            nn.ZeroPad2d((1,0,1,0)),\n            nn.Conv2d(512, 1, 4, padding=1)\n        )\n        \n    def forward(self, img):\n        return self.model(img)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:43.294597Z","iopub.execute_input":"2024-02-25T01:45:43.295781Z","iopub.status.idle":"2024-02-25T01:45:43.306763Z","shell.execute_reply.started":"2024-02-25T01:45:43.295734Z","shell.execute_reply":"2024-02-25T01:45:43.305634Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_m = nn.ZeroPad2d((0,0,0,1)) # Check Padding Function\ntest_m(tensor)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:38:07.297034Z","iopub.execute_input":"2024-02-19T23:38:07.297482Z","iopub.status.idle":"2024-02-19T23:38:07.316572Z","shell.execute_reply.started":"2024-02-19T23:38:07.297439Z","shell.execute_reply":"2024-02-19T23:38:07.315292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Loss Functions\ncriterion_GAN = torch.nn.MSELoss()\ncriterion_cycle = torch.nn.L1Loss()\ncriterion_identity = torch.nn.L1Loss()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:49.087431Z","iopub.execute_input":"2024-02-25T01:45:49.088046Z","iopub.status.idle":"2024-02-25T01:45:49.091910Z","shell.execute_reply.started":"2024-02-25T01:45:49.088014Z","shell.execute_reply":"2024-02-25T01:45:49.090995Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"input_shape = (channels, img_height, img_width) # (3,256,256)\nn_residual_blocks = 9 # suggested default, number of residual blocks in generator\n\nG_AB = GeneratorResNet(input_shape, n_residual_blocks)\nG_BA = GeneratorResNet(input_shape, n_residual_blocks)\nD_A = Discriminator(input_shape)\nD_B = Discriminator(input_shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:45:58.079778Z","iopub.execute_input":"2024-02-25T01:45:58.080156Z","iopub.status.idle":"2024-02-25T01:45:58.470791Z","shell.execute_reply.started":"2024-02-25T01:45:58.080129Z","shell.execute_reply":"2024-02-25T01:45:58.469618Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.02) # reset Conv2d's weight(tensor) with Gaussian Distribution\n        if hasattr(m, 'bias') and m.bias is not None:\n            torch.nn.init.constant_(m.bias.data, 0.0) # reset Conv2d's bias(tensor) with Constant(0)\n        elif classname.find('BatchNorm2d') != -1:\n            torch.nn.init.normal_(m.weight.data, 1.0, 0.02) # reset BatchNorm2d's weight(tensor) with Gaussian Distribution\n            torch.nn.init.constant_(m.bias.data, 0.0) # reset BatchNorm2d's bias(tensor) with Constant(0)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:00.487259Z","iopub.execute_input":"2024-02-25T01:46:00.487631Z","iopub.status.idle":"2024-02-25T01:46:00.495421Z","shell.execute_reply.started":"2024-02-25T01:46:00.487606Z","shell.execute_reply":"2024-02-25T01:46:00.494063Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"G_AB.apply(weights_init_normal)\nG_BA.apply(weights_init_normal)\n\nD_A.apply(weights_init_normal)\nD_B.apply(weights_init_normal)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:02.298256Z","iopub.execute_input":"2024-02-25T01:46:02.298660Z","iopub.status.idle":"2024-02-25T01:46:02.552635Z","shell.execute_reply.started":"2024-02-25T01:46:02.298628Z","shell.execute_reply":"2024-02-25T01:46:02.551641Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Discriminator(\n  (model): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n    (11): ZeroPad2d((1, 0, 1, 0))\n    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def temp_weights_init_normal(m):\n    classname =  m.__class__.__name__\n    print(classname)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:06.656871Z","iopub.execute_input":"2024-02-25T01:46:06.657835Z","iopub.status.idle":"2024-02-25T01:46:06.664465Z","shell.execute_reply.started":"2024-02-25T01:46:06.657793Z","shell.execute_reply":"2024-02-25T01:46:06.662502Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# G_AB.apply(temp_weights_init_normal)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T23:39:40.000317Z","iopub.execute_input":"2024-02-19T23:39:40.000755Z","iopub.status.idle":"2024-02-19T23:39:40.005972Z","shell.execute_reply.started":"2024-02-19T23:39:40.000721Z","shell.execute_reply":"2024-02-19T23:39:40.004950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize optimizers\nimport itertools\n\noptimizer_G = torch.optim.Adam(\n    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1,b2)\n)\n\noptimizer_D_A = torch.optim.Adam(\n    D_A.parameters(), lr=lr, betas=(b1,b2)\n)\noptimizer_D_B = torch.optim.Adam(\n    D_B.parameters(), lr=lr, betas=(b1,b2)\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:10.770348Z","iopub.execute_input":"2024-02-25T01:46:10.770737Z","iopub.status.idle":"2024-02-25T01:46:10.779782Z","shell.execute_reply.started":"2024-02-25T01:46:10.770709Z","shell.execute_reply":"2024-02-25T01:46:10.778076Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n# Schedule learning rates\nclass LambdaLR:\n    def __init__(self, n_epochs, offset, decay_start_epoch):\n        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n        self.n_epochs = n_epochs\n        self.offset = offset\n        self.decay_start_epoch = decay_start_epoch\n        \n    def step(self, epoch):\n        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:13.728626Z","iopub.execute_input":"2024-02-25T01:46:13.728996Z","iopub.status.idle":"2024-02-25T01:46:13.736601Z","shell.execute_reply.started":"2024-02-25T01:46:13.728970Z","shell.execute_reply":"2024-02-25T01:46:13.735231Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\nlr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n    optimizer_G,\n    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n)\n\nlr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n    optimizer_D_A,\n    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n)\nlr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n    optimizer_D_B,\n    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:15.800515Z","iopub.execute_input":"2024-02-25T01:46:15.800877Z","iopub.status.idle":"2024-02-25T01:46:15.808066Z","shell.execute_reply.started":"2024-02-25T01:46:15.800852Z","shell.execute_reply":"2024-02-25T01:46:15.806802Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Transform and collect images for training\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\ntransforms_ = [\n    transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n    transforms.RandomCrop((img_height, img_width)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n]","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:17.701623Z","iopub.execute_input":"2024-02-25T01:46:17.702172Z","iopub.status.idle":"2024-02-25T01:46:17.708843Z","shell.execute_reply.started":"2024-02-25T01:46:17.702071Z","shell.execute_reply":"2024-02-25T01:46:17.707568Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\n\ndef to_rgb(image):\n    rgb_image = Image.new(\"RGB\", image.size)\n    rgb_image.paste(image)\n    return rgb_image","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:19.962104Z","iopub.execute_input":"2024-02-25T01:46:19.962471Z","iopub.status.idle":"2024-02-25T01:46:19.968885Z","shell.execute_reply.started":"2024-02-25T01:46:19.962444Z","shell.execute_reply":"2024-02-25T01:46:19.967583Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torchvision.utils import make_grid\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n        self.transform = transforms.Compose(transforms_)\n        self.unaligned = unaligned\n        self.mode = mode\n        if self.mode == 'train':\n            self.files_A = sorted(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*')[:250])\n            self.files_B = sorted(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*')[:250])\n        elif self.mode == 'test':\n            self.files_A = sorted(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*')[250:])\n            self.files_B = sorted(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*')[250:301])\n\n    def  __getitem__(self, index):\n        image_A = Image.open(self.files_A[index % len(self.files_A)])\n        \n        if self.unaligned:\n            image_B = Image.open(self.files_B[np.random.randint(0, len(self.files_B)-1)])\n        else:\n            image_B = Image.open(self.files_B[index % len(self.files_B)])\n        if image_A.mode != 'RGB':\n            image_A = to_rgb(image_A)\n        if image_B.mode != 'RGB':\n            image_B = to_rgb(image_B)\n            \n        item_A = self.transform(image_A)\n        item_B = self.transform(image_B)\n        return {'A':item_A, 'B':item_B}\n    \n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:21.769668Z","iopub.execute_input":"2024-02-25T01:46:21.770090Z","iopub.status.idle":"2024-02-25T01:46:21.782452Z","shell.execute_reply.started":"2024-02-25T01:46:21.770060Z","shell.execute_reply":"2024-02-25T01:46:21.781094Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# initialize data-loading\ndataloader = DataLoader(\n    ImageDataset(root, transforms_=transforms_, unaligned=True),\n    batch_size=1, # 1\n    shuffle=True,\n    num_workers=n_cpu # 3\n)\n\nval_dataloader = DataLoader(\n    ImageDataset(root, transforms_=transforms_, unaligned=True, mode='test'),\n    batch_size=5,\n    shuffle=True,\n    num_workers=n_cpu\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:25.735910Z","iopub.execute_input":"2024-02-25T01:46:25.736472Z","iopub.status.idle":"2024-02-25T01:46:25.787171Z","shell.execute_reply.started":"2024-02-25T01:46:25.736434Z","shell.execute_reply":"2024-02-25T01:46:25.785764Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def sample_images():\n    \"\"\"show a generated sample from the test set\"\"\"\n    imgs = next(iter(val_dataloader))\n    G_AB.eval()\n    G_BA.eval()\n    real_A = imgs['A'].type(Tensor) # A : monet\n    fake_B = G_AB(real_A).detach()\n    real_B = imgs['B'].type(Tensor) # B : photo\n    fake_A = G_BA(real_B).detach()\n    # Arange images along x-axis\n    real_A = make_grid(real_A, nrow=5, normalize=True)\n    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n    real_B = make_grid(real_B, nrow=5, normalize=True)\n    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n    # Arange images along y-axis    \n    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n    plt.figure(figsize=(15, 15))\n    plt.imshow(image_grid.cpu().permute(1,2,0))\n    plt.title('Real A vs Fake B | Real B vs Fake A')\n    plt.axis('off')\n    plt.show();\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:27.233486Z","iopub.execute_input":"2024-02-25T01:46:27.233953Z","iopub.status.idle":"2024-02-25T01:46:27.242344Z","shell.execute_reply.started":"2024-02-25T01:46:27.233920Z","shell.execute_reply":"2024-02-25T01:46:27.241030Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"Tensor =  torch.Tensor","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:28.870676Z","iopub.execute_input":"2024-02-25T01:46:28.871953Z","iopub.status.idle":"2024-02-25T01:46:28.876926Z","shell.execute_reply.started":"2024-02-25T01:46:28.871909Z","shell.execute_reply":"2024-02-25T01:46:28.875713Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport warnings","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:30.672406Z","iopub.execute_input":"2024-02-25T01:46:30.672813Z","iopub.status.idle":"2024-02-25T01:46:30.677984Z","shell.execute_reply.started":"2024-02-25T01:46:30.672781Z","shell.execute_reply":"2024-02-25T01:46:30.677035Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epoch, 5): \n    for i, batch in enumerate(tqdm(dataloader)):\n        \n        # Set model input\n        real_A = batch['A'].type(Tensor)\n        real_B = batch['B'].type(Tensor)\n        \n        # Adversarial ground truths\n        valid = Tensor(np.ones((real_A.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n        fake = Tensor(np.zeros((real_A.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n        \n# -----------------\n# Train Generators\n# -----------------\n        G_AB.train() # train mode\n        G_BA.train() # train mode\n        \n        optimizer_G.zero_grad() # Integrated optimizer(G_AB, G_BA)\n        \n        # Identity Loss\n        loss_id_A = criterion_identity(G_BA(real_A), real_A) # If you put A into a generator that creates A with B,\n        loss_id_B = criterion_identity(G_AB(real_B), real_B) # then of course A must come out as it is.\n                                                             # Taking this into consideration, add an identity loss that simply compares 'A and A' (or 'B and B').\n        loss_identity = (loss_id_A + loss_id_B)/2\n        \n        # GAN Loss\n        fake_B = G_AB(real_A) # fake_B is fake-photo that generated by real monet-drawing\n        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid) # tricking the 'fake-B' into 'real-B'\n        fake_A = G_BA(real_B)\n        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid) # tricking the 'fake-A' into 'real-A'\n        \n        loss_GAN = (loss_GAN_AB + loss_GAN_BA)/2\n        \n        # Cycle Loss\n        recov_A = G_BA(fake_B) # recov_A is fake-monet-drawing that generated by fake-photo\n        loss_cycle_A = criterion_cycle(recov_A, real_A) # Reduces the difference between the restored image and the real image\n        recov_B = G_AB(fake_A)\n        loss_cycle_B = criterion_cycle(recov_B, real_B)\n        \n        loss_cycle = (loss_cycle_A + loss_cycle_B)/2\n        \n# ------> Total Loss\n        loss_G = loss_GAN + (10.0*loss_cycle) + (5.0*loss_identity) # multiply suggested weight(default cycle loss weight : 10, default identity loss weight : 5)\n        \n        loss_G.backward()\n        optimizer_G.step()\n        \n# -----------------\n# Train Discriminator A\n# -----------------\n        optimizer_D_A.zero_grad()\n    \n        loss_real = criterion_GAN(D_A(real_A), valid) # train to discriminate real images as real\n        loss_fake = criterion_GAN(D_A(fake_A.detach()), fake) # train to discriminate fake images as fake\n        \n        loss_D_A = (loss_real + loss_fake)/2\n        \n        loss_D_A.backward()\n        optimizer_D_A.step()\n\n# -----------------\n# Train Discriminator B\n# -----------------\n        optimizer_D_B.zero_grad()\n    \n        loss_real = criterion_GAN(D_B(real_B), valid) # train to discriminate real images as real\n        loss_fake = criterion_GAN(D_B(fake_B.detach()), fake) # train to discriminate fake images as fake\n        \n        loss_D_B = (loss_real + loss_fake)/2\n        \n        loss_D_B.backward()\n        optimizer_D_B.step()\n        \n# ------> Total Loss\n        loss_D = (loss_D_A + loss_D_B)/2\n         # Append losses to the lists\n        G_losses.append(loss_G.item())\n        D_losses.append(loss_D.item())\n        \n# -----------------\n# Show Progress\n# -----------------\n        if (i+1) % 10 == 0:\n            sample_images()\n            print('[Epoch %d/%d] [Batch %d/%d] [D loss : %f] [G loss : %f - (adv : %f, cycle : %f, identity : %f)]'\n                    %(epoch+1,n_epochs,       # [Epoch -]\n                      i+1,len(dataloader),   # [Batch -]\n                      loss_D.item(),       # [D loss -]\n                      loss_G.item(),       # [G loss -]\n                      loss_GAN.item(),     # [adv -]\n                      loss_cycle.item(),   # [cycle -]\n                      loss_identity.item(),# [identity -]\n                     ))\n             # Visualize generated samples\n            sample_images()\n\n            # Plot losses over training\n            plt.figure(figsize=(10, 5))\n            plt.title(\"Generator and Discriminator Loss During Training\")\n            plt.plot(G_losses, label=\"Generator\")\n            plt.plot(D_losses, label=\"Discriminator\")\n            plt.xlabel(\"Iterations\")\n            plt.ylabel(\"Loss\")\n            plt.legend()\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T01:46:40.777262Z","iopub.execute_input":"2024-02-25T01:46:40.777622Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eddf913403641f4a8e1d85f6273397d"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# ------> Total Loss\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         loss_G \u001b[38;5;241m=\u001b[39m loss_GAN \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m10.0\u001b[39m\u001b[38;5;241m*\u001b[39mloss_cycle) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m5.0\u001b[39m\u001b[38;5;241m*\u001b[39mloss_identity) \u001b[38;5;66;03m# multiply suggested weight(default cycle loss weight : 10, default identity loss weight : 5)\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m         \u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m         optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# -----------------\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Train Discriminator A\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# -----------------\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}